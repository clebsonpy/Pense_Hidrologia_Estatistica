{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jennifer A. Hoeting, David Madigan, Adrian E. Raftery and Chris T. Volinsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o seguinte cenário: um pesquisador coletou dados sobre o câncer do esôfago.  Para cada um de um grande número de pacientes, ela registrou uma variedade de covariáveis demográficas e médicas, juntamente com o último status de sobrevivência conhecido de cada paciente. Ela gostaria de avaliar o tamanho do efeito de cada covariada no tempo de sobrevivência com vistas a projetar futuras intervenções e, adicionalmente, gostaria de ser capaz de prever o tempo de sobrevivência de futuros pacientes. Ela decide usar modelos de regressão de riscos proporcionais para analisar os dados. Em seguida, ela conduz uma pesquisa orientada por dados para selecionar covariáveis para o modelo de regressão de riscos proporcionais específicos, M\\*, que fornecerá a estrutura para inferência subsequente. Ela verifica se M* se ajusta razoavelmente bem aos dados e observa que as estimativas dos parâmetros são sensíveis. Finalmente, ela continua a usar M* para estimar o tamanho dos efeitos e os erros padrão associados e fazer previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto pode aproximar a prática padrão da estatística, mas é totalmente satisfatório? Suponha que existe um modelo alternativo de perigo\n",
    "proporcionais, M\\*\\*, que também fornece um bom ajuste aos dados, mas leva a tamanhos de efeito estimadores substancialmente diferentes, erros padrão diferentes ou previsões diferentes? Nesta situação, como o pesquisador deve proceder? Modelos como M\\*\\* são comuns: para exemplos impressionantes ver Regal and Hook (1991), Draper (1995), Madigan and York (1995), Kass and Raftery (1995), e Raftery (1996). Basear as inferências apenas em M* é arriscado; presumivelmente, ambiguidade sobre a seleção de modelos a informação sobre a dimensão dos efeitos deve ser diluída e predições, uma vez que \"parte da evidência é gasta para especificar o modelo\" (Leamer, 1978, p. 91). Draper et al. (1987) e Hodges (1987) fazem essencialmente a mesma observação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cálculo da Bayesian Model Averaging (BMA) fornece uma forma de contornar este problema. Se $\\Delta$ é a quantidade de interesse, como um tamanho de efeito, um futuro observável, ou a utilidade de um curso de ação, então sua distribuição posterior D dada ao dados é\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(\\Delta|D) = \\sum_{k=1}^{K} pr(\\Delta|M_{k},D)pr(M_{k}|D)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma média das distribuições posteriores sob cada um dos modelos considerados, ponderada pela probabilidade do modelo posterior. Em (1), $M_1, ..., M_K$ são os modelos considerados. A probabilidade posterior para o modelo Mk é dada por\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(M_{k}|D) = \\frac{pr(D|M_{k})pr(M_{k})}{\\sum_{l=1}^{K} pr(D|M_{l})pr(M_{l})}\n",
    "\\end{equation}\n",
    "\n",
    "onde, $pr(D|M_{k}) = \\int pr(D|\\theta_{k}, M_{k})pr(\\theta_{k}|M_{k})d\\theta_{k}$ é a probabilidade intregrada do modelo $M_{k}$, $\\theta_{k}$ é o vetor de parâmetro para o modelo $M_{k}$ (e.g. para regressões $\\theta = (\\beta, \\sigma^{2})$), $pr(\\theta_{k}|M_{k})$ é a densiade priori de $\\theta_{k}$ sob o modelo $M_{k}$, $pr(D|\\theta_{k}, M_{k})$ é a probabilidade e $pr(M_{k})$ é a probabilidade a priori de que $M_{k}$ seja o modelo verdadeiro (considerando que um dado modelo seja verdadeiro). Todas as probabilidade são implicitamente condicionada por $M$ do conjunto de todos os modelos a serem considerados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A média posterior e a variância de A são as seguintes:\n",
    "\\begin{equation}\n",
    "    E(\\Delta|D) = \\sum_{k=0}^{K} \\hat{\\Delta}_{k}pr(M_{k},D)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    Var(\\Delta|D) = \\sum_{k=0}^{K} (Var[\\Delta|D, M_{k}] + \\hat{\\Delta}_{k}^{2})pr(M_{k}|D)E[\\Delta|D]^{2},\n",
    "\\end{equation}\n",
    "\n",
    "onde $\\hat{\\Delta}_{k} = E[\\Delta|D, M_{k}]$ (Raftery, 1993; Draper 1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Madigan e Raftery (1994) nota que o cálculo da média sobre todos os modelos, desta forma proporciona uma melhor capacidade de previsão da média, medida por uma regra de pontuação logarítmica, do que usar um único modelo $M_{j}$, condicional de M. Existem agora evidências empíricas consideráveis para apoiar esta afirmação teórica; na Seção 7, apresentaremos algumas destas evidências."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora BMA seja uma solução intuitivamente atraente para o problema de contabilizar incertezas para o modelo, ele ainda não faz parte do kit de ferramentas padrão para análise de dados. Isto é, em parte, devido ao fato que a implementação do BMA apresenta várias dificuldades, como notado, discutiremos nas secções deste artigo:\n",
    "- O número de termos em (1), pode ser enorme, exautivel somatório inviabilizaria a reprodução (Seção 3.1).\n",
    "- As integrais implicita em (1), pode, em geral, ser dificil de calcular. Método de cadeia de Markov via Monte Carlos, em parte, resolve o problema, mas questões tecnicar permanecem desafiadoras (Seção 3.2).\n",
    "- Especificamente para $pr(M_{k})$, a distribuição a priori sobre modelos concorrentes, é desafiador e tem recebido pouca atenção (Seção 5).\n",
    "- Depois que essas dificuldades são superadas, a escolha da classe de modelos sobre a qual a média se torna a tarefa fundamental de modelagem. Pelo menos três escolas de pensamento com peting surgiram (Seção 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este artigo deseja fornecer uma introdução tutorial sobre BMA e várias discursões para soluções para as dificuldades de solução. Discutiremos também brevemente os trabalhos relacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinação de modelos: Uma pespectiva histórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barnard (1963) forneceu a primeira menção de combinação de modelos na literatura estatística em um artigo estudando dados de passageiros aéreos. Contudo, a maior parte do trabalho inicial na combinação de modelos não estava em periódicos estatísticos. O trabalho de previsão seminal de Bates e Granger (1969) estimulou uma enxurrada de artigos na literatura económica dos anos 70 sobre a combinação de previsões de diferentes modelos de previsão. Ver Clemen (1989) para uma revisão detalhada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na literatura estatística, o trabalho inicial relacionado com o cálculo da média inclui Roberts (1965), que sugeriu uma distribuição que combina as opiniões de dois especialistas(ou modelos). Esta distribuição, essencialmente uma distribuição posteriori de média ponderada de dois modelos, é similar para BMA. Leamer (1978) expande esta ideia e apresenta o paradigma básico para BMA. Salientou a ideia fundamental que BMA é resposável pelas incertezas envolvendo a escolha do modelo. Após o livro de Leamer's ser públicado, pouca atenção foi dada à BMA. As desvantagens de descosiderar as incertezas dos modelos foram reconhecido por muitos autores (e.g. a coleção de artigos editado por Dijkstra, 1988), mas pouco progresso foi feito até o novos desenvolvimento teóricos e poder computacional permitiram que os pesquiasdores superar as dificuldades relacionadas à implementação do BMA (Seção 1). George (1999) revisor os modelos Bayesian selecionando e discutindo BMA no contexto da teoria da decisão. Draper (1995), Chatfield (1995), e Kass e Raftery (1995) todos revisaram BMA e os custos de ignorar as incertezas. Estes artigos foca mais na interpretação de Bayesian, considerando que enfatizaremos a implementação e outras questões práticas nestes artigos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando BMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, discuteremos uma geral questão de implemetação para BMA. Na seção 4, discutiremos modelos de classes específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerenciando o somatório"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho das classes de modelos interessantes torna frequentemente impraticável o processamento exaustivel do somatório (1). Descrevemos duas abordagens distintas para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira abordagem é calcular a média sobre uma subconjunto de modelos que são suportado pelos dados. O método Occam's window de Madigan e Raftery (1994) calcula média sobre o conjunto de parsimonious, dados suportado pelos modelos, selecionados através da aplicação de normas padrão de investigação científica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dois principios basicos por trás do método Occam's window. Primeiro, Madigan e Raftery (1994) argumenta que se um modelo prediz o dado distante menos bem do que modelos que providência as melhores predições, então foi efetivamente desacreditado e não deve mais ser considerado. Assim, os modelos que não pertencem a esta categoria devem ser excluídos de (1) em que C é escolhido pelo analista de dados.\n",
    "\n",
    "\\begin{equation}\n",
    "    A' = \\{ M_{k}: \\frac{max_{l}\\{pr(M_{l}|D)\\}}{pr(M_{k}|D} \\leq C \\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O seu segundo princípio, opcional, apelando para a lâmina de Occam's, levou-os a excluir modelos complexos que recebem menos suporte a partir dos dados que os seus homólogos mais simples. Mais formalmente, também excluem de (1) os modelos pertencentes a:\n",
    "\n",
    "\\begin{equation}\n",
    "    B = \\{ M_{k}: \\exists M_{l} \\in  A', M_{l} \\subset M_{k}, \\frac{pr(M_{l}|D)}{pr(M_{k}|D} > 1 \\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e (1) é substituído por:\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(\\Delta|D) = \\sum_{M_{k} \\subset A} pr(\\Delta|M_{k},D)pr(M_{k},D),\n",
    "\\end{equation}\n",
    "\n",
    "onde $A = A'/B$ e todas as probabilidade são implicitamente condicional sobre o conjunde de modelos em A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso reduz muito o número de modelos na soma em (1) e agora tudo o que é necessário é uma estratégia de pesquisa para identificar os modelos em $A$. Madigan e Raftery (1994) propôs uma estratégia de pesquisa possível, baseada em duas ideias principais. Primeiro, quando o algoritmo é comparado a dois modelos aninhados e descidimos rejeitar o modelo simples, então todos os submodelos do modelo mais simples são rejeitados. A segunda ideia, \"Occam's Window\", preocupações à interpretação da relação de modelo de probabilidade posterior $pr(M_{0}|D)/pr(M_{1}|D)$. Aqui $M_{0}$ é \"menor\" que $M_{1}$. O essencial da ideia mostramos em Figura 1: Se ai está a efidência para $M_{0}$ então $M_{1}$ é rejeitada, mas rejeitando $M_{0}$ requer forte evidência para o modelo maior, $M_{1}$. Se a evidência é inconclusiva (falhando em Occam's window), nenhum dos dois modelos é rejeitado. Madigan e Raftery (1994) adotaram 1/20 e 1 para $O_{L}$ e $O_{R}$, respectivamente (ver Figura 1). Raftery, Madigan and Volinsky (1996) mostra que adotando 1/20 e 20 para $O_{L}$ e $O_{R}$, respectivamente, pode fornecer melhor desempenho preditivo;  isto especifica $O_{L} = O_{R}^{1}$ que equivale a usar apenas o princípio da Occam's Window e não o segundo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses princípios inteiramente define a estrátegia. Na maioria das classes de modelos, o número de termos em (1) é tipicamente reduzido para menos de 100 modelos e frequentemente para menos de 10; uma redução para um ou dois modelos não é incomum. Madigan e Raftery (1994) fornece uma descrição detalhada para o algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma pra procurar outros modelos em d é sugerido por Volinsky, Madigan, Raftery and Kronmal (1997). Eles usam o algoritmo \"salto e limites\" (Furnival and Wilson, 1974) para identificar rapidamente os modelos para serem usados no somatório (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A segunda abordagem, a composição do modelo da cadeia de Markov Monte Carlo ($MC^{3}$), usa o método de cadeia de Markov Monte Carlo para aproximar (1) (Madigan and York, 1995). Especificamente, deixe $M$ denotar o espaço dos modelos em consideração. Pode-se construir uma cadeia de Markov $\\{M(t)\\}$, $t = 1, 2,$... com espaço de estado $M$ e distribuição de equilíbrio $pr(Mi|D)$ e simular esta cadeia de Markov obter observações $M(1)$, ..., $M(N)$. Então, para qualquer função $g(M_{i})$ definido em $M$, a média é estimda por $E(g(M))$. Aplicando os resultados padrão da cadeia de Markov Monte Carlo,\n",
    "\\begin{equation}\n",
    "    \\hat{G} \\rightarrow E(g(M)) N \\rightarrow a.s. as \\propto \n",
    "\\end{equation}\n",
    "\n",
    "(e.g., Smith and Roberts, 1993). Para calcular (1) nesta forma estabelece $g(M) = pr(\\Delta M, D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a construção da cadeia de Markov, define uma zona $ndb(M)$ para cada $M \\in M/$. Por exemplo, com modelos gráficos, a zona pode ser um conjunto de modelos com uma ligação a mais ou uma ligação a menos de M, mas o próprio modelo M. Defina uma matriz de transição q configurando $q(M \\rightarrow M') = 0$ para todos os $M' \\in nbd(M)$ e $q(M \\rightarrow M')$ não zero para todos os $M' \\in nbd(M)$. Se a cadeia estiver atualmente no estado $M$, proceda desenhando $M'$ de $q(M \\rightarrow M')$. $M'$ é aceito com probabilidade\n",
    "\n",
    "\\begin{equation}\n",
    "    min\\{1, \\frac{pr(M'|D)}{pr(M|D)}\\}.\n",
    "\\end{equation}\n",
    "\n",
    "Caso contrário, a cadeia permanece no estado $M$. Para uma introdução básica ao algoritmo Metropolis-Hastings, ver Chib e Greenberg (1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O $MC^{3}$ oferece uma flexibilidade considerável. Por exemplo, trabalhando com classes de equivalência de modelos gráficos, Madigan, Andersson, Perlman e Volinsky (1996a), introduziram uma ordenação total dos vértices no processo estocástico como uma variável auxiliar, fornecendo assim uma velocidade computacional tripla (ver Seção 4.4). York, Madigan, Heuch e Lie (1995) incorporaram dados ausentes e uma variável latente em seu esquema $MC^{3}$. Para os modelos lineares, Raftery, Madigan e Hoeting (1997) aplicaram $MC^{3}$ à média entre modelos com muitos preditores. No entanto, como em outros métodos de Monte Carlo da cadeia de Markov, as questões de convergência podem ser problemáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método de busca de seleção para variáveis estocástica (SSVS) de George e McCulloch (1993) é semelhante em a $MC^{3}$. Em SSVS, um preditor não é realmente removido do modelo completo; em vez disso, esses preditores são definidos como próximos de zero com alta probabilidade. Um procedimento de Monte Carlo da cadeia de Markov é então usado para mover-se pelo espaço do modelo e pelo espaço do parâmetro ao mesmo tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clyde, DeSimone e Parmigiani (1996) introduziram uma importante estratégia de amostragem baseada na reexpressão do espaço de modelos em termos de uma ortogonalização da matriz de projeto**. Seu objetivo é implementar a mistura de modelos para problemas com muitos preditores correlacionados. Uma vantagem desta abordagem é que a ortogonalização pode reduzir o número de modelos plausíveis concorrentes. **Quando a mistura de modelos ortogonais é apropriada, ela pode ser muito mais eficiente do que $MC^{3}**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalhos anteriores relacionados incluem Stewart (1987), que utilizou a importância da amostragem para calcular a média entre modelos de regressão logística, e Carlin e Polson (1991), que utilizaram a amostragem de Gibbs para misturar modelos com diferentes distribuições de erros. Besag, Green, Higdon e Mengerson (1995, Seção 5.6) usam uma abordagem de cadeia de Markov Monte Carlo para calcular a média entre famílias de distribuições t. Buntine (1992) aplicou BMA às árvores de classificação (CART). Ao invés de aversobre todas as árvores possíveis, o seu algoritmo procura árvores com elevada probabilidade posterior e médias sobre aqueles. Trabalhos relacionados anteriores incluem Kwok e Carter (1990)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métodos estocásticos que se movimentam simultaneamente no espaço do modelo e no espaço dos parâmetros abrem uma gama ilimitada de aplicações para BMA. Como a dimensionalidade do espaço de parâmetros geralmente muda com o modelo, os métodos padrão não se aplicam.  No entanto, trabalhos recentes de Carlin e Chib (1993), Philips e Smith (1994) e Green (1995) fornecem soluções potenciais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando integrais para BMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra dificuldade na implementação do BMA é que os integrais da forma (3) implícita em (1) podem ser difíceis de calcular. Para certas classes interessantes de modelos, tais como modelos gráficos discretos (e.g., Madigan e York, 1995) e regressão linear (e.g., Raftery, Madigan e Hoeting, 1997), integrais de forma fechada para a probabilidade marginal, (3), são avaliadas. O método de Laplace (Tierney e Kadane, 1986) pode fornecer uma excelente aproximação para $pr(D|Mk)$; em certas circunstâncias, isto resulta numa aproximação BIC muito simples (Schwarz, 1978; Kass e Wasserman 1995; Raftery, 1995). Taplin (1993) sugeriu a aproximação $pr(A | D)$ por $pr(A | Mk, 0, D)$ onde 0 é a estimativa de máxima verossimilhança parâmetro vector 0; referimo-nos a isto como a \"aproximação da EML\". Draper (1995), Raftery, Madigan e Volinsky (1996) e Volinsky et al. (1997) mostram a sua utilidade no contexto BMA. A Secção 4 discute estas aproximações com mais detalhe no contexto de modelos de classes específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalhes de implementação para modelos de classes específicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, descrevemos a implementação da estratégia geral da última seção para modelos de classes específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear: Preditores, Outiliers e Transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seleção de um conjunto de variável preditorias é parte básica para construção de um modelo de regressão linear. O objetivo da seleção de variáveis é tipicamente afirmar da seguinte forma: dada uma variável dependente Y e um conjunto de preditores candidatos $X_{1}, ..., X_{k}$, encontrar o \"melhor\" modelo da forma\n",
    "\n",
    "\\begin{equation}\n",
    "    Y = \\beta_{0} + \\sum_{j=1}^{p} \\beta_{ij}X_{ij} + \\varepsilon\n",
    "\\end{equation}\n",
    "\n",
    "onde $X_{i1}, ..., X_{ip}$ é um subconjunto de $X_{1}, ..., X_{k}$. Aqui, \"melhor\" pode ter vários significados, por exemplo, o modelo que fornece as previsões mais exatas para novos casos intercambiáveis com os utilizados para se adaptar ao modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, BMA procura calcular a média de todos os conjuntos possíveis de preditores.  Raftery, Madigan and Hoeting (1997) fornece uma expressão fechada para a máxima verossimilhança, uma ampla discussão sobre a escolha do hiperparâmetro na situação em que há pouca informação prévia disponível, e implementação detalhada de BMA para ambos Occam's window e $MC^{3}$. Fernández, Ley e Steel (1997, 1998) oferecer uma estrutura prévia alternativa com vista a uma escolha mais automática de hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeting, Raftery e Madigan (1996, 1999); daqui em diante HRM96 e HRM99, extende esta estrutura de modo a incluir as transformações e os outliers, respectivamente. Em grande parte por razões de conveniência, HRM99 usou a classe Box-Cox para transformações de potência para as respostas. A classe de transformações de potência Box-Cox muda o problema de selecionar uma transformação para uma estimação de parâmetro. O modelo é $Y^{\\rho} = X \\beta + \\varepsilon$ onde $\\varepsilon \\sim N(0, \\sigma^{2}I)$ e\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left\\{\\begin{matrix}\n",
    "        \\frac{y^{\\rho} + 1}{\\rho}, \\rho \\neq 0, & \\\\ \n",
    "        log(y), \\rho = 0. & \n",
    "    \\end{matrix}\\right.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enquanto a classe de tranformação de potência é matematicamente atrativa, transformação de potência, as transformações de potência normalmente não têm uma interpretação biológica ou física, a menos que se limitem a alguns valores possíveis de $\\rho$. A média de HRM99 é calculada sobre os valores (1, 0, 0.5, 1), para que os preditores transformados possam ser interpretados como o recíproco, o logaritmo, a raiz quadrada e a resposta não transformada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a transformação dos preditores, a HRM99 propôs uma nova abordagem que consiste em um uso exploratório inicial do algoritmo de expectativa condicional alternada (ACE), seguido de transformações de pontos de mudança, se necessário. O algoritmo ACE (Breiman and Friedman, 1985) fornece transformações não lineares, não-paramétricas das variáveis num modelo de regressão. ACE escolhe as transformações para maximizar a correlação entre a resposta transformada e a soma do predicto transformado. HRM99 usou ACE para sugerir transformações paramétricas dos preditores. As transformações sugeridas pelo ACE frequentemente têm aproximadamente a forma de um ponto de mudança, um limiar ou um efeito de saturação, sem mudança no valor esperado da resposta acima (ou abaixo) de um determinado valor. Este tipo de transformação frequentemente descreve melhor o contexto físico ou biológico assumido do experimento do que as transformações de potência comumente usadas discutidas acima. Para escolher o ponto de modificação e determinar a evidência para o ponto de modificação, a HRM99 forneceu uma estimativa do fator Bayes. As médias de BMA da HRM99 sobre todas as transformações de preditores para as quais a evidência excede um nível especificado pelo usuário. Isto é conseguido simplesmente ao incluir os preditores transformados como covariáveis extras para consideração em modelos potenciais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HRM96 calcula a média sobre conjuntos de preditores e possíveis outliers. Eles adotaram um modelo de variância-inflação para outliers da seguinte forma: Vamos $Y^{\\rho} = X \\beta + \\varepsilon$ onde os dados observados sobre os preditores estão contidos na matrix $X\\ (n\\ x\\ (p + 1))$ e os dados observados sobre a variável dependente estão contidos no n-vetor Y. Assumiram que os $\\varepsilon$'s em casos distintos são independentes quando\n",
    "\n",
    "\\begin{equation}\n",
    "    \\varepsilon \\sim \\left\\{\\begin{matrix}\n",
    "        N \\ (0, \\sigma^{2}), \\ \\ \\ \\ w.p.(1 \\ \\pi ), & \\\\ \n",
    "        N \\ (0, K^{2} \\sigma^{2}), \\ \\ \\  w.p. \\pi & \n",
    "     \\end{matrix}\\right.\n",
    "\\end{equation}\n",
    "\n",
    "Aqui $\\pi$ é a probabilidade de um outlier e $K^{2}$ é o parâmetro variância-inflação. \n",
    "\n",
    "Seu método de seleção simultânea de variável e outlier (SVO) envolve duas etapas. Num primeiro passo exploratório, utilizaram uma técnica altamente robusta para identificar um conjunto de potenciais aberrantes. A abordagem robusta tipicamente identifica um grande número de potenciais outliers. Na segunda etapa, a HRM96 calculou todas as probabilidades possíveis do modelo posteriori ou utilizou $MC^{3}$, considerando todos os subconjuntos possíveis do conjunto de possíveis outliers. Este método em duas etapas é computacionalmente viável e permite que grupos de observações sejam considerados simultaneamente como potenciais outliers. A HRM96 forneceu evidências de que a SVO identifica com sucesso outliers mascarados. Uma abordagem de seleção simultânea de variáveis, transformação e outlier (SVOT) que combina SVO e SVT também foi proposta (Hoeting, 94). No software BICREG está disponível uma implementação mais rápida mas menos exacta da BMA para a selecção de variáveis em regressão linear através do algoritmo de saltos e limites (secção 4.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Lineares Generalizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A construção de modelos para modelos lineares generalizados envolve a escolha das variáveis independentes, da função link e da função variância (McCullagh e Nelder, 1989). Cada combinação possível de escolhas define um modo diferente. Raftery (1996) apresenta métodos de cálculo de fatores Bayes aproximados para modelos lineares generalizados. O fator Bayes, $B_{10}$ para um modelo $M_{1}$ contra outro modelo $M_{O}$ dado o dado $D$, é a relação de posteriores, nomeadamente,\n",
    "\n",
    "\\begin{equation}\n",
    "    B_{10} = \\frac{pr(D|M_{1})}{pr(D|M_{0})}, \n",
    "\\end{equation}\n",
    "\n",
    "a relação da probabilidade marginal. Os fatores de Bayes, por sua vez, produzem probabilidades de modelos posteriores para todos os modelos, e habilitam a BMA, como segue. Suponha que (K + 1) modelos, $M_{O}, M_{1}, . . ., M_{K}$, estão sendo considerados. Cada um dos $M_{1}, . . ., M_{K}$ é comparado por sua vez com $M_{O}$, produzindo fatores Bayes $B_{10},..., B_{KO}$. Então a probabilidade posterior de $M{k}$ é\n",
    "\n",
    "\\begin{equation}\n",
    "    pr(M_{k}|D) = \\frac{\\alpha_{k}B_{k0}}{\\sum_{r=0}^{K} \\alpha_{r}B_{r0}},\n",
    "\\end{equation}\n",
    "\n",
    "onde $\\alpha_{k} = pr(M_{k})/pr(M_{0})$ é a chances a priori para $M_{k}$ contra $M_{0}$(k = 0, ..., K)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A derivação do Raftery procede da seguinte forma. Suponha que $Y_{i}$ é uma variável dependente e que $X_{i} = (x_{i},..., x_{ip})$ é um vetor correspondente de variáveis independentes, para i = 1, ..., n. Um modelo linear generalizado $M_{1}$ é definido especificando $pr(Y_{i} | X_{i}, \\beta)$ de tal forma que $E[Y_{i}|X_{i}] = \\mu_{i}$, $Var[Y_{i}|X_{i}] = \\sigma^{2}\\nu(\\mu_{i})$ e $g(\\mu_{i} = X_{i}\\beta)$, onde $\\beta = (\\beta_{1}, ..., \\beta{p})^{T}$; aqui g é chamado de função de ligação. A matrix n x m com os elementos $x_{ij}$ é denotada por X, e assume-se que $x_{i1} = 1$ (i = 1, ..., n). Aqui assumimos que $\\sigma^{2}$ é conhecido; Raftery (1996) trata do do caso $\\sigma^{2}$ desconhecido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o fator Bayes para o modelo nulo $M_{O}$, definido pelo ajuste $\\beta_{j}$ = 0 (j = 2, ..., p), contra $M_{1}$. A probabilidade para $M_{0} e M_{1}$ pode ser escrito explicitamente, e assim, uma vez que o prior tenha sido totalmente especificado, a seguinte aproximação (Laplace) pode ser computada:\n",
    "\n",
    "\\begin{equation}\n",
    "    p(D|M_{k})\\approx (2\\pi)^{p_{k}/2}|\\psi|^{1/2} pr(D|\\widetilde{\\beta_{k}}, M_{k})pr(\\widetilde{\\beta_{k}}|M_{k}),\n",
    "\\end{equation}\n",
    "\n",
    "onde $p_{k}$ é a dimensão para $\\beta_{k}$,  $\\widetilde{\\beta_{k}}$ é o modo posteriori de $\\beta_{k}$ e $\\psi_{k}$ é menos o inverso de Hessian $h(\\beta_k) = log\\{pr(D|\\beta_k, M_k)pr(\\beta_k|M_k)\\}$, avaliados em $\\beta_k = \\widetilde{\\beta_{k}}$. Argumentos semelhantes aos do Apêndice de Tierney e Kadane (1986) mostram que em modelos estatísticos regula o erro relativo em (10), e portanto na aproximação resultante do $B_{10}$, é O(n 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, esta aproximação não é fácil de calcular para modelos lineares generalizados usando software prontamente disponível, e Raftery (1996) apresenta três aproximações convenientes mas menos precisas. Reproduzimos aqui a mais precisa dessas aproximações. Suponha que a distribuição prévia de $\\beta_k$ é tal que $E[\\beta_k|M_k] = \\omega_k$ e $Var[\\beta_k|M_k] = W_k$. Então aproximadamente o modo posteriori, $\\tilde{\\beta_k}$, por um simples passo do algoritmo de Newton-Raphson (e.g., Kincaid e Cheney, 1991 page 26) a partir da MLE, $\\tilde{\\beta_k}$, e substituindo o resultado em (10) produz a aproximação\n",
    "\n",
    "\\begin{equation}\n",
    "    2logB_10 \\approx X^2 + (E_1 \\ E_2)\n",
    "\\end{equation}\n",
    "\n",
    "Em, $X^2 = 2\\{l_1(\\hat{\\beta_1}) \\ l_0(\\hat{\\beta_2})\\}$, onde $l_k(\\hat{\\beta_k}) = log(pr(D|\\beta_k, M_k))$ é a probabilidade logarítmica quando $M_{O}$ é aninhado dentro de $M_{1}$ e $x^2$ é a estatística padrão do teste de razão de verossimilhança. Tambem,\n",
    "\n",
    "ver no artigo\n",
    "\n",
    "Raftery (1996) descreve uma forma paramétrica útil para os parâmetros anteriores $\\omega_k$ e $W_k$ que envolve apenas uma entrada especificada pelo usuário e deriva uma forma de escolher isso quando pouca informação prévia está disponível. A distribuição prévia para, $\\beta$ tem três parâmetros especificados pelo usuário e Raftery (1996) discute possíveis escolhas na situação em que pouca informação prévia está disponível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Sobrevivência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os métodos de análise de dados de sobrevivência muitas vezes se concentram na modelagem da taxa de risco. A forma mais popular de fazer é utilizar o modelo de risco proporcional de Cox (Cox, 1972), que permite diferentes taxas de risco para casos de vetores covariados diferentes e deixa a taxa de risco comum subjacente não especificada. O modelo de Cox especifica que a taxa de perigo para o sujeito i com vetor $X_i$ com covariado seja\n",
    "\\begin{equation}\n",
    "    \\lambda (t|X_i) = \\lambda _o exp(X_i\\beta)\n",
    "\\end{equation}\n",
    "\n",
    "em que $\\lambda_0 (t)$ é a função de perigo de base no momento $t$ e $\\beta$ é um vector de parâmetros desconhecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estimativa de β é comumente baseada em probabilidade parcial, nomeadamente,\n",
    "\\begin{equation}\n",
    "    PL(\\beta) = \\prod_{i=1}^n\\left ( \\frac{exp(X_i\\beta)}{\\sum_{t\\in R_i}exp(X^T_l\\beta)} \\right )^{\\omega_{i}}\n",
    "\\end{equation}\n",
    "onde $R_i$ é o risco definido no tempo $t_i$ (ou seja, o conjunto de sujeitos que ainda não experimentaram um evento), e $\\omega_i$ é um indicador para saber se o paciente $i$ é ou não censurado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os integrais requeridos para BMA não possuem uma solução em formato fechado para os modelos Cox, Raftery, Madigan e Volinsky (1996) e Volinsky et al. (1997), a VMRK, a seguir, adotou uma série de aproximações. Em especial, a VMRK utilizou a aproximação da MLE,\n",
    "\\begin{equation}\n",
    "    pr(M_k, D) \\approx pr(M_k,\\hat{\\beta}_k, D)\n",
    "\\end{equation}\n",
    "\n",
    "e a aproximação de Laplace\n",
    "\\begin{equation}\n",
    "    log(pr(D|M_k) \\approx log(pr(D|\\hat{\\beta }_k, M_k)) - d_k log(n)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onde $d_k$ é a dimensão de $\\beta_k$. Esta é a aproximação do critério de informação Bayesiana (BIC). Em (13), $n$ é geralmente considerado o número total de casos. Volinsky (1997) fornece evidências de que $n$ deve ser o número total de casos não censurados (isto é, mortes ou eventos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar modelos BMA para Cox, VMRK usou uma abordagem similar ao método de janela do Occam descrito na Seção 3.1. Para identificar eficientemente bons modelos, a VMRK adaptou o algoritmo \"saltos e limites\" de Furnival e Wilson (1974), que foi originalmente criado para a seleção de modelos de regressão linear. Os saltos e o algoritmo de limites fornece o algoritmo top $q$ modelos de tamanho de cada modelo, onde $q$ é designado pelo usuário, mais a MLE $\\hat{\\beta}_k$, $var(\\hat{\\beta}_k)$, e $R^2_k$ para cada modelo $M_k$ devolvido. Lawless e Singhal (1978) e Kuk (1984) forneceram um algoritmo modificado para modelos de regressão não normais que dá uma estatística aproximada do teste de razão de verosimilhança e daí um valor aproximado de BIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde que $q$ seja grande o suficiente, este procedimento retorna os modelos na janela de Occam ($A$) mais muitos modelos não em $A$. A VMRK usou o teste de razão de verossimilhança aproximada para reduzir o subconjunto restante de modelos para aqueles com maior probabilidade de estar em $A$. Este passo de redução mantém apenas os modelos cujo valor aproximado probabilidades do modelo posterior caem dentro de um fator $C'$ do modelo com a maior probabilidade do modelo posterior, em que $C'$ é maior que $C$, o recorte em (4). (VMRK set $C' = C^2$ e quase nenhum modelo em foram perdido nos exemplos que consideraram). Um padrão análise de sobrevivência pode então analisar os modelos restantes, calcular o valor exato de BIC para cada um, e eliminar os modelos não em $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os modelos em $A$, a VMRK calculou as probabilidades do modelo posterior normalizando sobre o conjunto de modelos, como em (9). A média dos parâmetros estimados pelo modelo e os erros-padrão dessas estimativas derivam das médias ponderadas das estimativas e dos erros-padrão dos modelos individuais, usando as probabilidades dos modelos posteriores como pesos. A probabilidade posterior de que um coeficiente de regressão para uma variável seja diferente de zero (\"probabilidade de efeito posterior\") é simplesmente a soma das probabilidades posteriores dos modelos que contêm essa variável. No contexto de um exemplo real baseado no Cardiovascular Health Study (Fried et al., 1991), a VMRK mostrou que essas probabilidades de efeitos posteriores podem levar a interpretações substantivas que estão em desacordo com os valores-p usuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidades prévias no espaço do modelo bot e no espaço dos parâmetros são implicitamente definidas por este procedimento. Todos os modelos são considerados igualmente prováveis a priori pelo algoritmo de saltos e limites. Usando a aproximação BIC para a probabilidade integrada define um prior inerente em toda a regressão paramétricas, como descrito em Kass e Wasserman (1995). Este prior é um prior sensato para tomar em conta a ausência de informação prévia substancial; é uma distribuição normal centrada na hipótese nula. valor (geralmente 0) com a quantidade de informação em o prior igual ao montante médio de informação de uma observação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modelo gráfico é um modelo estatístico que incorpora um conjunto de relações de independência condicional que podem ser resumidas por meio de um gráfico. Até à data, a maior parte da pesquisa de modelos gráficos tem-se centrado em digrafos acíclicos, gráficos de cordas não direcionados e gráficos em cadeia que permitem ambos os lados direcionados e não direcionados, mas não têm ciclos parcialmente direcionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
